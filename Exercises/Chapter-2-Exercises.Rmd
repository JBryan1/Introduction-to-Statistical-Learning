---
title: "Chaper 2 Exercises"
author: "Jonathan Bryan"
date: "May 7, 2017"
output: html_document
---

### 1. For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.

#### (a) The sample size n is extremely large, and the number of predictors p is small.
Flexible models perform well when the sample size of the training set is large and a large number of parameters can be estimated to build the flexible model. Therefore a flexible model may be preferred.

#### (b) The number of predictors p is extremely large, and the number of observations n is small.
Flexible models can be difficult or impossible to fit when there are not enough observations available. A flexible model may also over fit the small number of observation, performing poorly on out-of-sample testing. Therefore a flexible model may not be preferred.

#### (C) The relationship between the predictors and response is highly non-linear.
Many flexible models can more easily and accurately model non-linear behavior so a non-linear model may be preferred.

#### (d) The variance of the error terms, i.e. $Ïƒ_2 = Var(\epsilon)$, is extremely high.
Flexible models tend to "chase" or closely follow the variation found in the training set data. This leads to high variability each time the model is run on different sets of training data. Therefore, increasing the variability of the noise in the data will increase the variability in the flexible model which is sub optimal. Therefore, a more flexible model may not be preferred.

### 2. Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.

#### (a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.
This is a regression problem with the goal of inference (n = 500 and p = 4).


#### (b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.
This is a classification problem with the goal of prediction (n = 20 and p = 13).


#### (c) We are interesting in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.
This is a regression problem with the goal of prediction (n = 366 and p = 3).

### 3. We now revisit the bias-variance decomposition. 

#### (a) Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.
```{r}
x = seq(1,100,1)
irre_y = rep(30,100)
train_y = (1/100)*(x-100)^2
bias_y = (1/150)*(x-100)^2
variance_y = (1/200)*(x)^(2.1)
test_y = bias_y + variance_y + irre_y


plot(irre_x, irre_y, xlim = c(0,100), ylim=c(0,100), xlab = "Model Flexibility", ylab = "Root Mean Squared Error", col = "black") #Irreducible error
lines(x,train_y, col="green", lwd = 2) #Training RMSE
lines(x,bias_y, col = "red", lwd = 2) #Squared Bias
lines(x,variance_y, col = "purple", lwd = 2) #Variance
lines(x,test_y, col = "blue", lwd = 2) #Testing RMSE
text(x = 10 , y = 25, labels = "Irreducible Error", cex = 0.8)
text(x = 70 , y = 20, labels = "Training RMSE", cex = 0.8, col="green")
text(x = 5 , y = 45, labels = "Squared Bias", cex = 0.8, col = "red")
text(x = 70 , y = 50, labels = "Variance", cex = 0.8, col = "purple")
text(x = 50 , y = 75, labels = "Testing RMSE", cex = 0.8, col = "blue" )
```

####(b)
Bias decreases as the model is better able to account for the variation in individual data points through increasingly flexibility and relaxing of persistent model constraints. Variance of the model increases as the model tracks the training data more closely and subsequent iterations of model generation produce very different results depending on the training data used. Training error consistently decreases as more flexible models are able to account for the variation in the training data and bias steadily decreases. Test error consistently decrease as the rate of bias reduction is higher than the rate of increase in model variance. Eventually, the rate of model variance overtakes the rate of model bias reduction and the overall test error begins to increase. The test error can not go below the level of irreducible error. Irreducible error is the level of measurement error inherent in the data and cannot be reduced in the model.

### 4. You will now think of some real-life applications for statistical learning.

#### (a) Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.

1. A zoologist wants to predict the taxonomy of animal remains found in a keystone predator. The zoologist has over 1,000 possible classifications of species and uses the genetic material to build the model. This is a classification problem with the goal of prediction.The response variable can be 1,000 different discrete categories that have no "order" or "ranking".

2. An investment firm wants to know whether positive or negative earnings reports by media companies are influenced by public sentiment on Twitter. This is an inferential classification problem with positive and negative earnings reports of media companies as the response and metrics that represent public sentiment on Twitter as the predictor variables.

3. A financial consulting company uses a stress test on banking clients to determine their firms ability to weather financial crises. The firm predicts has multiple different scenarios, each with a pass or fail response. The consulting company also uses the stress test to advise clients on best practices to avoid failure. This is a classification problem with both prediction and inference as a goal. The response is the multiple different stress test scenarios each with a pass or fail factor.


#### (b) Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.

1. A large retail chain wants to predict the change in a specific product's sales based upon the store placement and the combination of other store products in close proximity. This is a regression  question, where the response is the change in store sales and the predictors are store placement location and categorical variables representing different items placed next to the product.

2. An educational institution wants to predict graduate student's "grit" through physical and mental assessments. Grit is measured on a continuous numerical scale from 1 to 10, while the physical and mental assessments are a combination of categorical and numerical data. This is a regression problem with the goal of prediction. The response variable is grit while the assessment metrics are the predictors.

3. A healthcare system wants to understand the greatest sources of medical waste in dollars at the medical department level using data from physician, supply chain and medical records. This is a regression problem with the goal of inference. The response variable is the dollars of medical waste, on a continuous scale.


#### (c) Describe three real-life applications in which cluster analysis might be useful.

1. A large retail chain is testing a new product for launch and wants to segment the customer population currently buying the product in test markets. A Cluster analysis could be run to determine the distance "types" of customers who enjoy the product.

2. An oil exploration company would like to classify different types of oil extraction sites based upon return on investment, safety incidents, environmental impact, and other variables. There is no response variable so we can cluster the oil extraction sites based on similarity.

3. A toy company would like to market a new toy to a particular high-value customer segment. They would like to to know which attributes are clustered around different market segments and then blend those attributes together to create the new toy to appeal to the new customer segment. Cluster analysis can be run on the current toys to ascertain which attributes are closely associated and then match those clusters to market segments.


#### 8.
###(a)
```{r}
library(ISLR)
college = College
```

###(b)
```{r}
fix(college)
```

###(c)
```{r}
summary(college) #i
pairs(college[,1:10]) #ii
plot(college$Outstate,college$Private ) #iii

college$Elite = rep("No", nrow(college)) #iv
college$Elite[college$Top10perc > 50 ] = "Yes"
college$Elite = as.factor(college$Elite)
summary(college$Elite)#Number of elite colleges
plot(college$Outstate, college$Elite)

par(mfrow=c(2,2)) #v
hist(college$Accept)
hist(college$perc.alumni)
hist(college$Top10perc)
hist(college$Top25perc)

#vi Continue exploring data and brief summary
college_mcs = sapply(college, is.numeric)
college_mcs = college[college_mcs]
college_mcs = sapply(college_mcs, function(college_mcs) (college_mcs - mean(college_mcs))/sd(college_mcs))#mean centered and scaled data
boxplot(college_mcs)

plot(college$Elite, college$Apps)
```
We observe that many of the numeric variables have fat tail empirical distributions that skew towards positive values. We also observe that elite institutions receive many more applications than non-elite institutions.

#### 9. This exercise involves the Auto data set studied in the lab. Make sure that the missing values have been removed from the data.

### (a) Which of the predictors are quantitative, and which are qualitative?
```{r}
auto = Auto

categorical = sapply(auto, is.factor) #Determine which variables are categorical
print(paste0( "The categorical variable is: ",colnames(auto[categorical]))) #Get names of categorical variables

numeric = sapply(auto, is.numeric) #Determine which variables are categorical
print(paste0("The numeric variables are: ", colnames(auto[numeric]))) #Get names of categorical variables
```

### (b) What is the range of each quantitative predictor? You can answer this using the range() function.
```{r}
sapply(auto[numeric], range) #Range of each numeric variable
```

### (c) What is the mean and standard deviation of each quantitative predictor?
```{r}
print("Mean of each Numeric Variable")
sapply(auto[numeric], mean) #Mean of each numeric variable
print("Standard Deviation of each Numeric Variable")
sapply(auto[numeric], sd) #Standard deviation of each numeric variable
```

###(d) Now remove the 10th through 85th observations. What is the range, mean, and standard deviation of each predictor in the subset of the data that remains?
```{r}
auto_new = auto[-c(10,85),]

print("Mean of each Numeric Variable")
sapply(auto_new[numeric], mean) #Mean of each numeric variable
print("Standard Deviation of each Numeric Variable")
sapply(auto_new[numeric], sd) #Standard deviation of each numeric variable
```

###(e)
```{r}
pairs(auto)
plot(auto$mpg, auto$horsepower)
plot(auto$year, auto$mpg)

auto_mcs = scale(auto[numeric])#Mean center and scale data
boxplot(auto_mcs)
```
We observe that horsepower is seemingly negatively correlated with miles per gallon. The average miles per gallon a car has seems to be increasing over the time period given. Acceleration and horsepower seem to have possible outliers.

### (f) Suppose that we wish to predict gas mileage (mpg) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting mpg? Justify your answer.


