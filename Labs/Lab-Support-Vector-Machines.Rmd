---
title: 'Lab: Support Vector Machines'
author: "Jonathan Bryan"
date: "August 21, 2018"
output: pdf_document
---
```{r echo = FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5) 
```

### 9.6.1 Support Vector Classifier
```{r}
#create simulated data
set.seed(1)
x = matrix(rnorm(20*2), ncol=2)
y = c(rep(-1,10), rep(1,10))
x[y==1,] = x[y==1,] + 1
plot(x, col=(3-y))
```

```{r}
#encode response as a factor
dat = data.frame(x = x, y = as.factor(y))
library(e1071)

#model linear svm classfier
svmfit = svm(y~., data = dat,
                  kernel = "linear",
                  cost = 10,
                  scale = FALSE)

plot(svmfit,dat) #plot of linear support vector
svmfit$index #index of support vectors
summary(svmfit)
```

```{r}
#model linear svm classifier with smaller cost function
svmfit = svm(y ~., data = dat,
                   kernel = "linear",
                   cost = 0.1,
                   scale = FALSE)
plot(svmfit, dat)
svmfit$index
```

```{r}
#svm cross-validation
set.seed(1)
tune.out = tune(svm,
                y~.,
                data = dat,
                kernel = "linear",
                ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```

```{r}
#access best cv model
bestmod = tune.out$best.model
summary(bestmod)
```

```{r}
#generate test observations
xtest = matrix(rnorm(20*2), ncol = 2)
ytest = sample(c(-1,1), 20, rep = TRUE)
xtest[ytest==1,] = xtest[ytest==1,] + 1
testdat = data.frame(x=xtest, y = as.factor(ytest))

#svm prediction with best cv model
ypred = predict(bestmod, testdat)
table(predict = ypred, truth = testdat$y)
```

```{r}
#svm prediction with smaller cost value
svmfit = svm(y~., 
             data=dat,
             kernel = "linear",
             cost = 0.01,
             scale = FALSE)
ypred = predict(svmfit, testdat)
table(predict = ypred,
      truth = testdat$y)
```

```{r}
#modify training data to be linearly separable
x[y==1,]=x[y==1,] + 0.5
plot(x, col = (y+5)/2, pch =19)
```

```{r}
#svm with high cost value to increase training accuracy
dat = data.frame(x=x,
                 y = as.factor(y))
svmfit = svm(y~.,
             data = dat,
             kernel = "linear",
             cost = 1e5)
summary(svmfit)
plot(svmfit, dat)
```

```{r}
#smaller cost value
svmfit = svm(y~.,
             data = dat,
             kernel = "linear",
             cost = 1)
summary(svmfit)
plot(svmfit, dat)
```

### 9.6.2 Support Vector Machine
```{r}
#non-linear data generation
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)
x[1:100,] = x[1:100,]+2
x[101:150,]=x[101:150,]-2
y=c(rep(1,150), rep(2,50))
dat = data.frame(x=x,
                 y=as.factor(y))
plot(x,col=y)
```

```{r}
#svm with radial kernel and gamma = 1
train = sample(200,100)
svmfit = svm(y~.,
             data=dat[train,],
             kernel = "radial",
             gamma = 1,
             cost = 1)
plot(svmfit, dat[train,])
summary(svmfit)
```

```{r}
svmfit = svm(y~.,
             data = dat[train,],
             kernel = "radial",
             gamma = 1,
             cost = 1e5)
plot(svmfit, dat[train,])
```

```{r}
#radial svm cross-validation
set.seed(1)
tune.out = tune(svm, 
                y~.,
                data = dat[train,],
                kernel = "radial",
                ranges = list(cost = c(0.1,1,10,100,1000),
                gamma = c(0.5, 1, 2, 3, 4)))
summary(tune.out)
```

```{r}
#test set accuracy
table(true=dat[-train,"y"],
      pred = predict(tune.out$best.model,newdata=dat[-train,])
      )
```

### 9.6.3 ROC Curves
```{r}
library(ROCR)
rocplot = function(pred, truth,...){
                  predob = prediction(pred, truth)
                  perf = performance(predob, "tpr", "fpr")
                  plot(perf,...)
}
```

```{r}
#obtain fitted training set values for svm
svmfit.opt = svm(y~.,
                 data = dat[train,],
                 kernel = "radial",
                 gamma = 2,
                 cost = 1,
                 decision.values = TRUE)
fitted = attributes(predict(svmfit.opt,
                          dat[train,],
                          decision.values = TRUE))$decision.values
rocplot(fitted,
        dat[train,"y"],
        main = "Training Data")

svmfit.flex = svm(y~.,
                  data=dat[train,],
                  kernel = "radial",
                  gamma=50,
                  cost=1,
                  decision.values=TRUE)
fitted = attributes(predict(svmfit.flex,
                            dat[train,],
                            decision.values=TRUE))$decision.values
rocplot(fitted,
        dat[train,"y"],
        add = TRUE,
        col= "red")
```

```{r}
#obtain fitted values of radial svm on test data
fitted = attributes(predict(svmfit.opt,
                            dat[-train,],
                            decision.values = TRUE))$decision.values
rocplot(fitted, 
        dat[-train,"y"],
        main = "Test Data")
fitted = attributes(predict(svmfit.flex,
                            dat[-train,],
                            decision.values = TRUE))$decision.values
rocplot(fitted,
        dat[-train,"y"],
        add = TRUE,
        col = "red")
```

### SVM with Multiple Classes
```{r}
#multiple class data generation
set.seed(1)
x=rbind(x, matrix(rnorm(50*2), ncol = 2))
y=c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat = data.frame(x=x,
                 y=as.factor(y))
par(mfrow = c(1,1))
plot(x,col=(y+1))

#radial svm
svmfit=svm(y~., 
           data=dat, 
           kernel="radial", 
           cost=10,
           gamma = 1)
plot(svmfit,dat)
```

### 9.6.5 Application to Gene Expression Data
```{r}
library(ISLR)

#EDA of gene expression data
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain)
table(Khan$ytest)
```

```{r}
#svm classifier with linear kernel
dat = data.frame(x=Khan$xtrain,
                 y=as.factor(Khan$ytrain)
                 )
out = svm(y~.,
          data = dat,
          kernel = "linear",
          cost =10)
summary(out)

#training prediction
table(out$fitted, dat$y)
```

```{r}
dat.te = data.frame(x=Khan$xtest,
                    y=as.factor(Khan$ytest)
                    )
pred.te = predict(out, newdata = dat.te)
table(pred.te, dat.te$y)
```