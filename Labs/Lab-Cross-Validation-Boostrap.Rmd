---
title: "Lab: Cross-Validation and the Bootstrap"
author: "Jonathan Bryan"
date: "May 18, 2018"
output: pdf_document
---

### 5.3.1 The Validation Set Approach
```{r}
library(ISLR)

#Sample random integers to extract data from the Auto set
set.seed(1)
train = sample(nrow(Auto), nrow(Auto)/2)

#Linear regression
lm.fit = lm(mpg~horsepower, data=Auto, subset = train)

#MSE
mean((Auto$mpg-predict(lm.fit, Auto))[-train]^2)
```

```{r}
#Polynomial (2) linear regression
lm.fit2 = lm(mpg~poly(horsepower,2), data = Auto, subset = train)

#MSE
mean((Auto$mpg-predict(lm.fit2, Auto))[-train]^2)
```

```{r}
#Polynomial (3) linear regression
lm.fit3 = lm(mpg~poly(horsepower,3), data = Auto, subset = train)

#MSE
mean((Auto$mpg-predict(lm.fit3, Auto))[-train]^2)
```

```{r}
#Repeating OLS fits with different seed
set.seed(2)
train = sample(nrow(Auto), nrow(Auto)/2)

#Linear regression
lm.fit = lm(mpg~horsepower, data=Auto, subset = train)
lm.fit2 = lm(mpg~poly(horsepower,2), data = Auto, subset = train)
lm.fit3 = lm(mpg~poly(horsepower,3), data = Auto, subset = train)

#MSE
mean((Auto$mpg-predict(lm.fit, Auto))[-train]^2)
mean((Auto$mpg-predict(lm.fit2, Auto))[-train]^2)
mean((Auto$mpg-predict(lm.fit3, Auto))[-train]^2)
```

### 5.3.2 Leave-One-Out Cross-Validation
```{r}
#Demonstration of equivalence between glm and lm
glm.fit = glm(mpg~horsepower, data=Auto)
coef(glm.fit)
```

```{r}
lm.fit = glm(mpg~horsepower, data=Auto)
coef(lm.fit)
```

```{r}
library(boot)

glm.fit=glm(mpg~horsepower, data=Auto)
cv.err = cv.glm(Auto, glm.fit)
cv.err$delta
```

```{r}
#LOOCV test error average with polynomial functions up to 5
cv.error = rep(NA,5)
for (i in 1:5){
  glm.fit = glm(mpg~poly(horsepower,i), data=Auto)
  cv.error[i] = cv.glm(Auto,glm.fit)$delta[1]
}
cv.error
```

### 5.3.3 k-Fold Cross-Validation
```{r}
#LOOCV test error average with polynomial functions up to 10
set.seed(17)
cv.error.10 = rep(NA,10)
for (i in 1:10){
  glm.fit = glm(mpg~poly(horsepower,i), data=Auto)
  cv.error.10[i] = cv.glm(Auto,glm.fit, K=10)$delta[1]
}
cv.error.10
```

### 5.3.4 The Bootstrap
```{r}
#Functon to calculate alpha for investment portfolio
alpha.fn= function(data,index){
  X = data$X[index]
  Y = data$Y[index]
  return ((var(Y)-cov (X,Y))/(var(X)+var(Y) -2* cov(X,Y)))
}

alpha.fn(Portfolio,1:100)
```

```{r}
set.seed(1)
alpha.fn(Portfolio,sample(100,100,replace=T))
```

```{r}
#Bootstrap function
boot(data = Portfolio, statistic = alpha.fn, R = 1000)
```

```{r}
#Bootstrap estimates for linear regression coefficients (using full data)
boot.fn = function(data, index){
  return(coef(lm(mpg~horsepower, data = data,subset = index)))
}
boot.fn(Auto, 1:392)  
```

```{r}
#Randomly sampling all observations with replacement
set.seed(1)
boot.fn(Auto,sample(392,392, replace = T)) 
boot.fn(Auto,sample(392,392, replace = T)) 
```

```{r}
boot(data = Auto, statistic = boot.fn, R = 1000)
```

```{r}
summary(lm(mpg~horsepower, data=Auto))$coef
```

```{r}
boot.fn = function(data,index){
  return(coef(lm(mpg~horsepower +I( horsepower ^2), data = data, subset=index)))
}
set.seed(1)
boot(data = Auto, statistic = boot.fn, R = 1000)
```

```{r}
summary(lm(mpg~horsepower +I(horsepower ^2) ,data=Auto))$coef
```